{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Data: [['Name', 'Temperature', 'Time', 'Date', 'Age (years)'], ['Charlie Day', '39.8', '21:47:43', '9/4/2024', 'NULL'], ['Charlie', '36.2', '3:10:43', '9/14/2024', '24'], ['Bob', '36.5', '18:35:43', '9/28/2024', '52'], ['Eva', 'NULL', '19:31:43', '7/28/2024', '64'], ['Eva', '38.2', '15:51:43', '9/5/2024', '75'], ['Eva', '38.5', '7:03:43', '4/12/2024', '23'], ['Alice', '39', '16:21:43', '4/16/2024', '43'], ['David', '39.6', '4:16:43', '3/27/2024', '26'], ['Eva', '36.1', '3:43:43', '6/15/2024', '75'], ['Bob', '35.2', '16:59:43', '6/27/2024', '31']]\n",
      "Dependent Data: [['Temp', 'Timestamp', 'Day Recorded', 'Status', 'Full Name'], ['95', '5:53 AM', '14/12/2023', 'High', 'David'], ['95', '2:27 AM', '6/12/2023', 'Normal', 'Charlie'], ['101.3', '5:29 PM', '12/2/2024', 'Elevated', 'Charlie'], ['100.4', '7:16 PM', '9/9/2024', 'Normal', 'Alice'], ['98.8', '12:52 AM', '13/10/2023', 'Normal', 'Alice'], ['96.3', '7:35 AM', '19/02/2024', 'Elevated', 'Alice'], ['100.4', '12:03 AM', '3/10/2024', 'Elevated', 'David'], ['97.1', '11:35 PM', '1/8/2024', 'High', 'David'], ['97.2', '3:06 PM', '11/10/2024', 'High', 'Bob'], ['98.7', '9:17 AM', '30/12/2023', 'Elevated', 'Charlie']]\n"
     ]
    }
   ],
   "source": [
    "# File paths for master and dependent data\n",
    "FILE_PATH_MASTER = 'data.csv'\n",
    "FILE_PATH_DEPENDENT = 'data2.csv'\n",
    "NULL_REP = 'NULL'\n",
    "\n",
    "def open_csv_file(file_path):\n",
    "    master_data = []\n",
    "    \n",
    "    if os.path.exists(file_path):  # Check if the file exists\n",
    "        with open(file_path, mode='r', newline='') as file:\n",
    "            reader = csv.reader(file)\n",
    "            k = next(reader)\n",
    "            length = len(k)\n",
    "            file.seek(0)\n",
    "            for row in reader:\n",
    "                # Ensure the row has the correct length\n",
    "                if len(row) < length:\n",
    "                    row.append(NULL_REP)\n",
    "                \n",
    "                # Replace all empty strings '' with NULL_REP\n",
    "                row = [NULL_REP if item == '' else item for item in row]\n",
    "                \n",
    "                master_data.append(row)\n",
    "\n",
    "    else:\n",
    "        # Create a new file if it does not exist\n",
    "        print(f\"The file '{file_path}' does not exist. Creating a new file.\")\n",
    "        with open(file_path, mode='w', newline=''):\n",
    "            pass  # Just create an empty file\n",
    "\n",
    "    return master_data\n",
    "\n",
    "# Load master and dependent data\n",
    "master_data = open_csv_file(FILE_PATH_MASTER)\n",
    "dependent_data = open_csv_file(FILE_PATH_DEPENDENT)\n",
    "\n",
    "# Optionally print out the loaded data for verification\n",
    "print(\"Master Data:\", master_data)\n",
    "print(\"Dependent Data:\", dependent_data)\n",
    "\n",
    "master_row_count = len(master_data) - 1\n",
    "dependent_row_count = len(dependent_data) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class for all data fields\n",
    "class DataField:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.class_name = self.__class__.__name__.lower() # Store class name automatically\n",
    "\n",
    "    def display(self):\n",
    "        raise NotImplementedError(\"Subclasses must implement this method.\")\n",
    "\n",
    "# Subclass for each specific category\n",
    "class Name(DataField):\n",
    "    def convert(self):\n",
    "        self.value = [name.split()[0].capitalize() for name in self.value]\n",
    "\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}\"\n",
    "\n",
    "class Date(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}\"\n",
    "\n",
    "class Time(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}\"\n",
    "\n",
    "class Temperature(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}Â°C\"\n",
    "\n",
    "class Status(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}\"\n",
    "\n",
    "class Address(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}\"\n",
    "\n",
    "class ID(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}\"\n",
    "\n",
    "class PhoneNumber(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}\"\n",
    "\n",
    "class Email(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}\"\n",
    "\n",
    "class Price(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: ${self.value}\"\n",
    "\n",
    "class Quantity(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}\"\n",
    "\n",
    "class Age(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value} years\"\n",
    "\n",
    "class Gender(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value}\"\n",
    "\n",
    "class Weight(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value} kg\"\n",
    "\n",
    "class Height(DataField):\n",
    "    def display(self):\n",
    "        return f\"{self.class_name}: {self.value} m\"\n",
    "\n",
    "\n",
    "# Factory for creating DataField instances\n",
    "class DataFieldFactory:\n",
    "    @staticmethod\n",
    "    def create_data_field(field_type, value):\n",
    "        field_classes = {\n",
    "            \"name\": Name,\n",
    "            \"date\": Date,\n",
    "            \"time\": Time,\n",
    "            \"temperature\": Temperature,\n",
    "            \"status\": Status,\n",
    "            \"address\": Address,\n",
    "            \"id\": ID,\n",
    "            \"phone_number\": PhoneNumber,\n",
    "            \"email\": Email,\n",
    "            \"price\": Price,\n",
    "            \"quantity\": Quantity,\n",
    "            \"age\": Age,\n",
    "            \"gender\": Gender,\n",
    "            \"weight\": Weight,\n",
    "            \"height\": Height,\n",
    "        }\n",
    "        \n",
    "        field_class = field_classes.get(field_type.lower())\n",
    "        if not field_class:\n",
    "            raise ValueError(f\"Unknown data field type: {field_type}\")\n",
    "        \n",
    "        return field_class(value)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def display_data(fields):\n",
    "    for field in fields:\n",
    "        print(field.display())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: ['Name', 'Temperature', 'Time', 'Date', 'Age (years)']\n",
      "Assigned Categories: {'name': <__main__.Name object at 0x000001E87FBEF410>, 'temperature': <__main__.Temperature object at 0x000001E87FBBAF90>, 'time': <__main__.Time object at 0x000001E87FBED400>, 'date': <__main__.Date object at 0x000001E87FD24860>, 'age': <__main__.Age object at 0x000001E87FD27CE0>}\n",
      "Column Names: ['Temp', 'Timestamp', 'Day Recorded', 'Status', 'Full Name']\n",
      "Assigned Categories: {'temperature': <__main__.Temperature object at 0x000001E87FD26B40>, 'time': <__main__.Time object at 0x000001E87FD24920>, 'status': <__main__.Status object at 0x000001E87FD27290>, 'name': <__main__.Name object at 0x000001E87FD24770>}\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "# Threshold for categorizing column names\n",
    "CATEGORY_THRESHOLD = 10\n",
    "\n",
    "def get_column_values(file_data, index):\n",
    "    \"\"\"\n",
    "    Retrieves all values from a specified column index in the given data.\n",
    "    \n",
    "    Args:\n",
    "        file_data (list): 2D list containing data.\n",
    "        index (int): The index of the column to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of values from the specified column.\n",
    "    \"\"\"\n",
    "    column_values = []\n",
    "    for row in file_data[1:]:  # Skip the header row\n",
    "        column_values.append(row[index])\n",
    "    return column_values\n",
    "\n",
    "def levenshtein_distance(str1, str2):\n",
    "    \"\"\"\n",
    "    Calculates the Levenshtein distance between two strings.\n",
    "    \n",
    "    Args:\n",
    "        str1 (str): The first string.\n",
    "        str2 (str): The second string.\n",
    "\n",
    "    Returns:\n",
    "        int: The Levenshtein distance.\n",
    "    \"\"\"\n",
    "    m, n = len(str1), len(str2)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    # Initialize base cases\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i \n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j \n",
    "\n",
    "    # Compute the distances\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            cost = 0 if str1[i - 1] == str2[j - 1] else 1 \n",
    "            dp[i][j] = min(\n",
    "                dp[i - 1][j] + 1,\n",
    "                dp[i][j - 1] + 1,\n",
    "                dp[i - 1][j - 1] + cost\n",
    "            )\n",
    "    \n",
    "    return dp[m][n]  # Return the distance\n",
    "\n",
    "def categorize_column(column_name, categories):\n",
    "    \"\"\"\n",
    "    Categorizes a column based on the minimum Levenshtein distance \n",
    "    compared to known categories.\n",
    "    \n",
    "    Args:\n",
    "        column_name (str): The name of the column to categorize.\n",
    "        categories (list): A list of category names and variations.\n",
    "\n",
    "    Returns:\n",
    "        str: The category assigned to the column.\n",
    "    \"\"\"\n",
    "    current_category = \"etc\"\n",
    "    min_distance = CATEGORY_THRESHOLD\n",
    "\n",
    "    for category_row in categories[1:]:  # Skip the header\n",
    "        category_name = category_row[0]\n",
    "        for other_name in category_row[1:]:\n",
    "            distance = levenshtein_distance(other_name.lower(), column_name.lower())\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                current_category = category_name\n",
    "                \n",
    "    return current_category\n",
    "\n",
    "def categorize_all_columns(data_table, categories):\n",
    "    \"\"\"\n",
    "    Categorizes all columns in the data table based on the defined categories.\n",
    "    \n",
    "    Args:\n",
    "        data_table (list): The 2D list representing the data table.\n",
    "        categories (list): The categories to compare against.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the key is the column name, and the value is the DataField instance.\n",
    "    \"\"\"\n",
    "    table_categories = {}\n",
    "    \n",
    "    # Iterate over column names\n",
    "    for j, column_name in enumerate(data_table[0]):\n",
    "        current_category = categorize_column(column_name, categories)\n",
    "        column_values = get_column_values(data_table, j)\n",
    "        \n",
    "        # Create a DataField instance for the categorized column and store it in the dictionary\n",
    "        table_categories[current_category] = DataFieldFactory.create_data_field(current_category, column_values)\n",
    "\n",
    "    print(\"Column Names:\", data_table[0])\n",
    "    print(\"Assigned Categories:\", table_categories)\n",
    "    return table_categories\n",
    "\n",
    "# Example usage\n",
    "categories = open_csv_file('categories_data.csv')\n",
    "master_categories = categorize_all_columns(master_data, categories)\n",
    "dependent_categories = categorize_all_columns(dependent_data, categories)\n",
    "\n",
    "# Convert the first master category for demonstration\n",
    "master_categories['name'].convert()\n",
    "print('Processing completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: name, Values: ['Charlie', 'Charlie', 'Bob', 'Eva', 'Eva', 'Eva', 'Alice', 'David', 'Eva', 'Bob', 'David', 'Charlie', 'Charlie', 'Alice', 'Alice', 'Alice', 'David', 'David', 'Bob', 'Charlie']\n",
      "Key: temperature, Values: ['39.8', '36.2', '36.5', 'NULL', '38.2', '38.5', '39', '39.6', '36.1', '35.2', '95', '95', '101.3', '100.4', '98.8', '96.3', '100.4', '97.1', '97.2', '98.7']\n",
      "Key: time, Values: ['21:47:43', '3:10:43', '18:35:43', '19:31:43', '15:51:43', '7:03:43', '16:21:43', '4:16:43', '3:43:43', '16:59:43', '14/12/2023', '6/12/2023', '12/2/2024', '9/9/2024', '13/10/2023', '19/02/2024', '3/10/2024', '1/8/2024', '11/10/2024', '30/12/2023']\n",
      "Key: date, Values: ['9/4/2024', '9/14/2024', '9/28/2024', '7/28/2024', '9/5/2024', '4/12/2024', '4/16/2024', '3/27/2024', '6/15/2024', '6/27/2024', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL']\n",
      "Key: age, Values: ['NULL', '24', '52', '64', '75', '23', '43', '26', '75', '31', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL']\n",
      "Key: status, Values: ['NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'High', 'Normal', 'Elevated', 'Normal', 'Normal', 'Elevated', 'Elevated', 'High', 'High', 'Elevated']\n",
      "Data successfully written to 'databaseOutput.csv' in column format.\n"
     ]
    }
   ],
   "source": [
    "# Takes the primary field and appends the secondary field, fills missing data with NULL_REP\n",
    "def mergeTables(master_data, dependent_data):\n",
    "    merged_data = master_data.copy()\n",
    "    all_keys = list(master_data.keys())\n",
    "    \n",
    "    # Append keys from secondary_data that aren't in master_data\n",
    "    all_keys.extend([column_key for column_key in dependent_data.keys() if column_key not in master_data])\n",
    "\n",
    "    for column_key in all_keys:\n",
    "\n",
    "        # if the master_data does not have a key, will fill in NULL\n",
    "        if column_key not in master_data:\n",
    "            null_filled_values = [NULL_REP for _ in range(master_row_count)]\n",
    "            merged_data[column_key] = DataFieldFactory.create_data_field(column_key, null_filled_values)\n",
    "        \n",
    "        # Append depentent data if it exists for a key\n",
    "        if column_key in dependent_data and dependent_data[column_key].value:\n",
    "            merged_data[column_key].value.extend(dependent_data[column_key].value)\n",
    "        # Append NULL_REP if no value exists in depentent_data\n",
    "        else:\n",
    "\n",
    "            merged_data[column_key].value.extend([NULL_REP for _ in range(dependent_row_count)])\n",
    "\n",
    "    # Print all values for each key in the merged_data\n",
    "    for column_key in merged_data:\n",
    "        print(f\"Key: {column_key}, Values: {merged_data[column_key].value}\")\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "merged_data = mergeTables(master_categories, dependent_categories)\n",
    "\n",
    "# Write to csv file in column fashion\n",
    "with open('databaseOutput.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers (keys)\n",
    "    column_keys = list(merged_data.keys())\n",
    "    writer.writerow(column_keys)\n",
    "\n",
    "    # Determine the maximum number of rows (longest list in merged_data)\n",
    "    max_length = max(len(merged_data[column_key].value) for column_key in column_keys)\n",
    "\n",
    "    # Write rows by transposing the lists in merged_data\n",
    "    for i in range(max_length):\n",
    "        row = [merged_data[column_key].value[i] if i < len(merged_data[column_key].value) else NULL_REP for column_key in column_keys]\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Data successfully written to 'databaseOutput.csv' in column format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
